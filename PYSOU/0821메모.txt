■상관관계 분석(correlation analysis)

상관관계 분석은 두 개의 대상이 서로간에 얼마나 관련이 있는지, 없는지 파악을 하는데 사용함. 회귀분석을 하기에 앞서서, 두 대상이 얼마나 관련이 있는지 선행자료로 사용함.

데이터 간의 밀도는 상관계수의 수치를 사용해 관계의 정도를 파악할 수 있음.
변수간 관련성 분석, 관계의 친밀함을 수치로 표현 가능.
그래프 상의 점들 사이의 밀도(분산값)이 촘촘할 수록, 머신러닝에 유리함.

ex) 광고비와 매출액 사이의 관련성 분석, 광고량과 브랜드 인지도의 관련성 분석

상관계수 r과 상관관계 정도

상관계수는 밀도를 숫자로 표현함. 밀도를 가지고 상관관계를 정확하게 표현하기 힘들기 때문에, 숫자화 시켜야 함.
숫자화 시킬때 사용하는 것은 피어슨 상관계수로, -1 ~ 1 사이의 값을 갖고, 1에 가까울수록 그래프상에서 우상향 & 밀도가 촘촘, 0에 가까울 수록 무관(상관관계가 없음, 일반적으로 0.2 이하는 상관관계가 없는 것으로 간주함.), -1에 가까울수록 우하향 & 밀도가 촘촘함.


상관계수는 선형일때만 구할 수 있으며, 비선형(그래프 상 U자 모양 등)에선 구할 수 없음.

상관분석은 만능이 아님. 상관분석은 두 변수간에 어떤 관계가 있는지를 파악할 순 있지만, 서로가 직접적인 영향을 주는지에 대한 인과관계는 파악할 수 없음. (ex. 아이스크림 판매량과 날파리 증가 수가 우상향이라 해도, 날파리가 많을 수록 아이스크림이 잘 팔린다라는 인과관계라고 생각할 수 없음.) 상관관계가 높다고 해서 한 변수가 다른 변수의 원인이 된다고 단정할 순 없음. 따라서 이후 과정으로는 회귀분석으로 넘어가야 함.

상관분석은 기본적으로 변수가 두 개 이상이며, 평균에서 치우침이 두 변수의 값에 의해 발생하기 때문에 분산 외에 공분산을 알아야 함.

공분산은 두 개 이상의 확률변수에 대한 값을 보여주는 값으로, 공분산을 이용하면 두 변수의 힘의 방향(패턴)을 알아낼 수 있게됨. 다만, 얼마나 관련있는지는 알 수 없기 때문에 표준화 작업(숫자화)이 필요함.

공분산을 표준화 시킨것이 상관계수로, 두 변수의 공분산을 각각의 표준편차의 곱으로 나눠서 구함.(파이썬에선 당연히, 미리 만들어진 매서드로 구함.)


■회귀분석(Regression Analysis)

회귀분석은 일반적으로 예측(정량적 예측, 숫자로)을 목표로 하는 통계 분석으로, 예측을 하는 방법에 핵심이 되는 개념이 바로 '추세선'임. 데이터 산포도를 바탕으로 좌표상에서 데이터의 분포와 앞으로의 변화를 잘 설명할 수 있는 하나의 선을 그려내는 것이 회귀분석의 목표.

회귀분석은 기계학습-지도학습에서 인간이 모델에게 학습시키는 데에 사용됨.

회귀분석 모델을 선택할 때 고려해야할 요소는 독립변수의 수, 종속 변수의 유형, 그리고 회귀선의 형태 3가지임. 회귀분석 모델은 3가지 종류로, 선형회귀(Linear Regression), 비선형회귀(Non Linear Regression), 로지스틱 회귀(Logistic Regression) 3가지임.

회귀분석의 그래프에서 x축은 독립변수, y축은 종속변수임. 선형회귀는 y = wx + b 형태의 단순한 1차방정식 추세선을 가짐. w와 b의 값을 구하는 전통적인 방법은 최소제곱법을 사용함. 그러나, 데이터들의 분포도까지는 알 수 없기 때문에, 상관계수를 이용해야 함. 상관계수가 1에 가까울수록 밀도가 높고 추세선에 가까움.

결정계수(R²)는 선형회귀모델의 성능을 평가하는 대표적 지표로, 일반적인 기준으로는
 0.0 ~ 0.3 설명력이 매우 낮음 → 모델 개선 필요
 0.3 ~ 0.5 어느 정도 경향 설명 가능 (탐색적 분석, 사회과학 데이터에서는 종종 수용)
 0.5 ~ 0.7 중간 수준의 설명력, 실무에서 "쓸 만하다"고 보는 경우 있음
 0.7 ~ 0.9 높은 설명력, 예측 모델로서 꽤 신뢰할 수 있음
 0.9 이상 매우 높은 설명력 (단, 과적합 가능성 주의)
으로 판단함. 따라서, 결정계수는 최소 몇 이상이라는 절대적인 기준은 없음. 종속변수는 결정계수는 상관계수를 제곱해서 구해질 수 있음.

회귀분석에서 F-value는 

*** 선형회귀분석의 기존 가정 충족 조건 ***
. 선형성 : 독립변수(feature)의 변화에 따라 종속변수도 일정 크기로 변화해야 한다.
. 정규성 : 잔차항(오차항)이 정규분포를 따라야 한다.
. 독립성 : 독립변수의 값이 서로 관련되지 않아야 한다.
. 등분산성 : 그룹간의 분산이 유사해야 한다. 독립변수의 모든 값에 대한 오차들의 분산은 일정해야 한다. (독립변수가 여러개일 때만 확인.)
. 다중공선성 : 다중회귀 분석 시 두 개 이상의 독립변수 간에 강한 상관관계가 있어서는 안된다. (독립변수가 여러개일 때만 확인.)

위 조건들을 충족하는 모델이 아닌 모델은 쓸모 없음.


다중공선성 : 다중공성선은 상관관계가 매우 높은 독립변수들이 동시에 모델에 포함될 때 발생함. 다중공선성이 있으면 특정 변수에 대한 효과를 제대로 측정할 수 없기 때문에 제거해야 함. 다중공선성을 확인하는 방법은 산포도 및 상관계수 확인, 허용/공차 확인, 분산팽창지수(VIF, Variance Inflation Factor) 확인이 있음. VIF가 크다는 것은 다중공선성이 크다는 의미로, 일반적으로 10보다 크면 문제가 있다고 판단함. 만약, 더미변수의 VIF가 3이상이라면, 다중공선성을 의심해야 함.

다중공선성을 해결하는 방법은 크게 다섯가지로, 1. 다중공선성을 유발하는 변수를 제거, 2. 주성붑분석으로 변수를 재조합, 3. 다중공선성이 발생한 독립변수들을 합침, 4. 능동회귀분석(Ridge), 5. Mean Centering 방법이 있음.


선형회귀의 평가지표:
MAE(Mean Absolute of Errors) 평균절대오차, MSE(Mean Square of Errors) 평균제곱오차, RMSE(Root Mean Square of Errors) 평균제곱오차제곱근, R2(R Squared Score) 결정계수 4가지가 있음.



train_test_split : 모델을 만들려면 학습데이터를 만들어야 함. 지금까진 전체 데이터로 학습을 하고 모델의 성능을 파악하는데 썻지만, 그럴 경우 잘 나올 수밖에 없음. 따라서, 전체데이터 중 일부만 잘라서 사용하고, 성능테스트를 할 때만 전체데이터를 쓰는 것이 바람직함. 그러나, 일부만 잘라서 사용할 때 전체데이터에 대비해서 패턴이 다르거나 편향되어있을 경우, 모델이 왜곡됨. train_test_split는 sklearn이 지원하는 메서드로, 전체 데이터를 자동으로 왜곡 걱정 없이 트레이닝 데이터와 테스트 데이터로 나눠줌. 일반적으로 트레이닝 데이터와 테스트 데이터는 7:3 혹은 8:2 비율로 나눔.



■비선형 회귀
비선형회귀는 직선의 회귀선을 곡선으로 변환해 보다 더 정확하게 데이터 변화를 예측하기 위해 사용함.
비선형회귀는 회귀선이 직선이 아닌 곡선인 특성상, 잔차가 더 적으며, 덕분에 실측과 추세선 사이의 표준오차가 더 작음.

비선형 회귀의 단점으로는 오버피팅될 우려가 있음. 특히나, 열이 많이 추가될 경우, 모델의 성능이 개선되나, 더 오버피팅됨.


■로지스틱 회귀
로지스틱 회귀는 선형회귀에서 발전한, 수학을 사용하여 두 데이터 요인간의 관계를 찾는 데이터 분석 기법으로, 독립변수는 연속형, 종속변수는 범주형일때 사용함. 로지스틱 회귀는 분류성능이 뛰어나진 않지만, 인공지능(Deep Learning) 및 기계학습 분야에서 중요한 기법으로, 어떤 범주에 속할 확률을  0에서  1사이의 값으로 예측하고, 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류하는 기법임.

로지스틱 회귀의 회귀선은 선형회귀와 마찬가지로 y = wx + b이지만, 출력 결과는 선형회귀와 달리 출력값이 연속형(확률)자료임.
이 확률을 기반으로 가능도 함수(Likelihood)를 정의하고, 그 가능도를 최대화 하는 파라미터(w, b)를 찾는 것이 로지스틱 회귀의 핵심 목적임.

로지스틱 회귀 분석은 수학에서 로지스틱 함수 또는 로짓 함수를 x와 y 사이의 방정식으로 사용하는 통계 모델로, 로짓 함수는 y를 x의 시그모이드 함수로 매칭함.

로지스틱 함수의 특징으로는 확률 대신 오즈비(odds ratio)를 사용한다. 오즈(odds)는 어떤 사건이 발생할 확률을 사건이 발생하지 않을 확룰로 나눈 값이다. (ex: 성공확률이 0.8이면 오즈 = 0.8/0.2 = 4) 오즈비(odds ratio)는 두 집단의 오즈 비율이다.

로지스틱 함수는 음의 무한대부터 양의 무한대까지의 실수값을 0부터 1사이의 실수값으로 1 대 1 대응시키는 시그모이드함수임. 로지스틱 회귀에서 wx+b로 얻은 값(로짓)은 −∞부터 +∞ 사이의 값이다. 이를 sigmoid 함수에 넣으면 값이 0~1 사이의 확률값으로 변환된다. 이 확률값을 기준(일반적으로 0.5)으로 0 또는 1 클래스로 분류(이항분류)할 수 있음.

로지스틱 회귀의 성능 분석(분류성능평가)은 confusion matrix(오차행렬)를 사용한다. confusion matrix는 참음성, 참양성, 위음성, 위양성이 표시된 행렬로, Accuracy(정확도)를 참음성 + 참양성을 전체 행렬의 값으로 나눠서 구한다.




로지스틱 회귀 분석의 과정은 : 
 ①  wx + b → 시그모이드 함수 → 확률 출력
 ②  확률을 가지고 각 샘플의 가능도 계산
 ③  전체 데이터에 대한 가능도 함수 정의
 ④  계산 편의를 위해 로그 가능도 사용
 ⑤  로그 가능도의 부호를 반전시켜 손실 함수 (Log Loss) 정의
 ⑥  이 손실을 최소화하여 최적의 w, b를 학습


로지스틱 회귀은 인공신경망의 단층 퍼셉트론과 동일한 구조이며, 해당 퍼셉트론이 여러개(다층신경망)이면 deep learning이 가능함.







■기계학습(machine learning)

기계학습은 수 많은 알고리즘들과 그 정답을 컴퓨터에게 학습시켜서 패턴을 파악하게 해서 모델을 만들어 냄. 컴퓨터는 모델을 이용해서 결과를 예측할 수 있게 됨.

기계학습은 지도학습, 비지도학습, 강화학습 세 가지 종류가 있음.

지도학습
지도학습은 사람이 직접 개입하는 학습법

비지도학습
비지도학습은 컴퓨터 스스로 패턴을 찾아내게 하는 학습법

강화학습(보상학습)



